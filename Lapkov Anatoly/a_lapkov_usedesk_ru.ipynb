{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Untick/Usedesk/blob/main/Lapkov%20Anatoly/a_lapkov_usedesk_ru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: TF_CPP_MIN_LOG_LEVEL=3\n"
          ]
        }
      ],
      "source": [
        "%env TF_CPP_MIN_LOG_LEVEL=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, BatchNormalization, Embedding, Flatten, Activation, Input, concatenate\n",
        "from tensorflow.keras.layers import SimpleRNN, GRU, LSTM, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, Adadelta, SGD, Adagrad, RMSprop\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_confirm_token(response):\n",
        "  for key, value in response.cookies.items():\n",
        "    if key.startswith('download_warning'):\n",
        "      return value\n",
        "  return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "  CHUNK_SIZE = 32768\n",
        "  with open(destination, 'wb') as f:\n",
        "    for chunk in response.iter_content(CHUNK_SIZE):\n",
        "      if chunk:\n",
        "        f.write(chunk)\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "  URL = 'https://docs.google.com/uc?export=download'\n",
        "  session = requests.Session()\n",
        "  response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "  token = get_confirm_token(response)\n",
        "  if token:\n",
        "    params = { 'id' : id, 'confirm' : token }\n",
        "    response = session.get(URL, params = params, stream = True)\n",
        "  save_response_content(response, destination)    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ImbJJ8RbOfZ5"
      },
      "outputs": [],
      "source": [
        "FILE_1_ID = '1PwMWQUCETRusiWN9hep2-12GWkdBrpkR'\n",
        "FILE_1_NAME = 'file_1.xlsx'\n",
        "FILE_2_ID = '1cCjgzBbSsBnzEfRQ9NgIv_ZVjmRywoqV'\n",
        "FILE_2_NAME = 'file_2.xlsx'\n",
        "FILES = {\n",
        "    FILE_1_ID: FILE_1_NAME,\n",
        "    FILE_2_ID: FILE_2_NAME\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "for id in FILES:\n",
        "    if not os.path.exists(FILES[id]):\n",
        "        download_file_from_google_drive(id, FILES[id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_1_data = pd.read_excel(FILE_1_NAME)\n",
        "file_1_data.drop(columns = [file_1_data.columns[0], file_1_data.columns[1]], axis = 1, inplace = True)\n",
        "file_2_data, file_2_links = pd.read_excel(FILE_2_NAME, sheet_name = [0, 2]).values()\n",
        "file_2_data.drop(columns = file_2_data.columns[0], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comp_id_new</th>\n",
              "      <th>всего</th>\n",
              "      <th>есть ответ</th>\n",
              "      <th>закрыт</th>\n",
              "      <th>nps</th>\n",
              "      <th>email</th>\n",
              "      <th>telephony</th>\n",
              "      <th>usedesk_chat</th>\n",
              "      <th>telegram</th>\n",
              "      <th>whatsapp</th>\n",
              "      <th>...</th>\n",
              "      <th>question</th>\n",
              "      <th>medium</th>\n",
              "      <th>правила_cnt</th>\n",
              "      <th>правила_dist</th>\n",
              "      <th>nps_avg</th>\n",
              "      <th>u_question</th>\n",
              "      <th>u_medium</th>\n",
              "      <th>licens</th>\n",
              "      <th>бз</th>\n",
              "      <th>бз_ст</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3709</td>\n",
              "      <td>3442</td>\n",
              "      <td>2466</td>\n",
              "      <td>1231</td>\n",
              "      <td>1317</td>\n",
              "      <td>0</td>\n",
              "      <td>779</td>\n",
              "      <td>737</td>\n",
              "      <td>778</td>\n",
              "      <td>...</td>\n",
              "      <td>3376</td>\n",
              "      <td>2568</td>\n",
              "      <td>42221</td>\n",
              "      <td>66</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5573</td>\n",
              "      <td>5301</td>\n",
              "      <td>4715</td>\n",
              "      <td>2004</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>1248</td>\n",
              "      <td>1125</td>\n",
              "      <td>1089</td>\n",
              "      <td>...</td>\n",
              "      <td>5107</td>\n",
              "      <td>3735</td>\n",
              "      <td>57044</td>\n",
              "      <td>62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6138</td>\n",
              "      <td>5983</td>\n",
              "      <td>5496</td>\n",
              "      <td>2242</td>\n",
              "      <td>1991</td>\n",
              "      <td>0</td>\n",
              "      <td>1440</td>\n",
              "      <td>1222</td>\n",
              "      <td>1378</td>\n",
              "      <td>...</td>\n",
              "      <td>5611</td>\n",
              "      <td>4114</td>\n",
              "      <td>69050</td>\n",
              "      <td>64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>7834</td>\n",
              "      <td>7664</td>\n",
              "      <td>7094</td>\n",
              "      <td>2851</td>\n",
              "      <td>2519</td>\n",
              "      <td>0</td>\n",
              "      <td>1856</td>\n",
              "      <td>1559</td>\n",
              "      <td>1765</td>\n",
              "      <td>...</td>\n",
              "      <td>7191</td>\n",
              "      <td>5313</td>\n",
              "      <td>89475</td>\n",
              "      <td>62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>7344</td>\n",
              "      <td>7252</td>\n",
              "      <td>6657</td>\n",
              "      <td>2686</td>\n",
              "      <td>2377</td>\n",
              "      <td>0</td>\n",
              "      <td>1764</td>\n",
              "      <td>1552</td>\n",
              "      <td>1596</td>\n",
              "      <td>...</td>\n",
              "      <td>6724</td>\n",
              "      <td>4894</td>\n",
              "      <td>82568</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11774</th>\n",
              "      <td>465</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11775</th>\n",
              "      <td>466</td>\n",
              "      <td>88</td>\n",
              "      <td>12</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>87</td>\n",
              "      <td>87</td>\n",
              "      <td>473</td>\n",
              "      <td>18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11776</th>\n",
              "      <td>466</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11777</th>\n",
              "      <td>467</td>\n",
              "      <td>57</td>\n",
              "      <td>55</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>51</td>\n",
              "      <td>39</td>\n",
              "      <td>182</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11778</th>\n",
              "      <td>468</td>\n",
              "      <td>121</td>\n",
              "      <td>91</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>121</td>\n",
              "      <td>113</td>\n",
              "      <td>241</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11779 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       comp_id_new  всего  есть ответ  закрыт   nps  email  telephony  \\\n",
              "0                1   3709        3442    2466  1231   1317          0   \n",
              "1                1   5573        5301    4715  2004   2008          0   \n",
              "2                1   6138        5983    5496  2242   1991          0   \n",
              "3                1   7834        7664    7094  2851   2519          0   \n",
              "4                1   7344        7252    6657  2686   2377          0   \n",
              "...            ...    ...         ...     ...   ...    ...        ...   \n",
              "11774          465     11          11       0     0     10          0   \n",
              "11775          466     88          12      84     0      3          0   \n",
              "11776          466      7           7       0     0      7          0   \n",
              "11777          467     57          55      25     1     10          0   \n",
              "11778          468    121          91     100     0     10          0   \n",
              "\n",
              "       usedesk_chat  telegram  whatsapp  ...  question  medium  правила_cnt  \\\n",
              "0               779       737       778  ...      3376    2568        42221   \n",
              "1              1248      1125      1089  ...      5107    3735        57044   \n",
              "2              1440      1222      1378  ...      5611    4114        69050   \n",
              "3              1856      1559      1765  ...      7191    5313        89475   \n",
              "4              1764      1552      1596  ...      6724    4894        82568   \n",
              "...             ...       ...       ...  ...       ...     ...          ...   \n",
              "11774             0         0         0  ...        10      10            5   \n",
              "11775             0        85         0  ...        87      87          473   \n",
              "11776             0         0         0  ...         7       7            0   \n",
              "11777             0        47         0  ...        51      39          182   \n",
              "11778             0       111         0  ...       121     113          241   \n",
              "\n",
              "       правила_dist  nps_avg  u_question  u_medium  licens  бз  бз_ст  \n",
              "0                66      0.0           2         2      13   1      4  \n",
              "1                62      0.0           5         5      13   1      4  \n",
              "2                64      0.0           1         1      13   1      4  \n",
              "3                62      0.0           6         6      13   1      4  \n",
              "4                60      0.0           2         2      13   1      4  \n",
              "...             ...      ...         ...       ...     ...  ..    ...  \n",
              "11774             1      0.0           0         0      10   0      0  \n",
              "11775            18      0.0           2         2       9   0      0  \n",
              "11776             0      0.0           0         0       9   0      0  \n",
              "11777             6      1.0           2         2       3   1      1  \n",
              "11778             7      0.0           0         0       7   0      0  \n",
              "\n",
              "[11779 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "corr_wodate_abs = file_2_data.drop('дата', axis = 1).drop('месяц_desc', axis = 1).corr() #.abs()\n",
        "corr_high = corr_wodate_abs[(corr_wodate_abs['рейтинг'] >= 0.05) & (corr_wodate_abs['рейтинг'] < 1.)]\n",
        "# display(corr_wodate_abs.sort_values('рейтинг', ascending = False).head(10))\n",
        "corr_cols = corr_high.index.to_list()\n",
        "# display(corr_cols)\n",
        "# display(len(corr_cols))\n",
        "corr_data = file_2_data[corr_cols]\n",
        "display(corr_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11779, 21)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004147</td>\n",
              "      <td>0.009890</td>\n",
              "      <td>0.002941</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005704</td>\n",
              "      <td>0.006634</td>\n",
              "      <td>0.007492</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003776</td>\n",
              "      <td>0.002872</td>\n",
              "      <td>5.459389e-03</td>\n",
              "      <td>0.095791</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006920</td>\n",
              "      <td>0.006920</td>\n",
              "      <td>0.067039</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.001496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006232</td>\n",
              "      <td>0.015231</td>\n",
              "      <td>0.005624</td>\n",
              "      <td>0.019846</td>\n",
              "      <td>0.002250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.009138</td>\n",
              "      <td>0.010127</td>\n",
              "      <td>0.010487</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005712</td>\n",
              "      <td>0.004177</td>\n",
              "      <td>7.376078e-03</td>\n",
              "      <td>0.089985</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017301</td>\n",
              "      <td>0.017301</td>\n",
              "      <td>0.067039</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.001496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006864</td>\n",
              "      <td>0.017191</td>\n",
              "      <td>0.006556</td>\n",
              "      <td>0.022203</td>\n",
              "      <td>0.002231</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010544</td>\n",
              "      <td>0.011000</td>\n",
              "      <td>0.013271</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006275</td>\n",
              "      <td>0.004601</td>\n",
              "      <td>8.928515e-03</td>\n",
              "      <td>0.092888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003460</td>\n",
              "      <td>0.003460</td>\n",
              "      <td>0.067039</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.001496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008760</td>\n",
              "      <td>0.022021</td>\n",
              "      <td>0.008462</td>\n",
              "      <td>0.028234</td>\n",
              "      <td>0.002822</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013590</td>\n",
              "      <td>0.014034</td>\n",
              "      <td>0.016998</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008042</td>\n",
              "      <td>0.005942</td>\n",
              "      <td>1.156957e-02</td>\n",
              "      <td>0.089985</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020761</td>\n",
              "      <td>0.020761</td>\n",
              "      <td>0.067039</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.001496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008212</td>\n",
              "      <td>0.020837</td>\n",
              "      <td>0.007940</td>\n",
              "      <td>0.026600</td>\n",
              "      <td>0.002663</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012917</td>\n",
              "      <td>0.013971</td>\n",
              "      <td>0.015370</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007520</td>\n",
              "      <td>0.005473</td>\n",
              "      <td>1.067646e-02</td>\n",
              "      <td>0.087083</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006920</td>\n",
              "      <td>0.006920</td>\n",
              "      <td>0.067039</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.001496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11774</th>\n",
              "      <td>0.993576</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>6.465253e-07</td>\n",
              "      <td>0.001451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050279</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11775</th>\n",
              "      <td>0.995717</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000765</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>6.116130e-05</td>\n",
              "      <td>0.026125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006920</td>\n",
              "      <td>0.006920</td>\n",
              "      <td>0.044693</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11776</th>\n",
              "      <td>0.995717</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044693</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11777</th>\n",
              "      <td>0.997859</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>2.353352e-05</td>\n",
              "      <td>0.008708</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.006920</td>\n",
              "      <td>0.006920</td>\n",
              "      <td>0.011173</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.000374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11778</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000134</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>3.116252e-05</td>\n",
              "      <td>0.010160</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033520</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11779 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2         3         4         5    6   \\\n",
              "0      0.000000  0.004147  0.009890  0.002941  0.012191  0.001476  0.0   \n",
              "1      0.000000  0.006232  0.015231  0.005624  0.019846  0.002250  0.0   \n",
              "2      0.000000  0.006864  0.017191  0.006556  0.022203  0.002231  0.0   \n",
              "3      0.000000  0.008760  0.022021  0.008462  0.028234  0.002822  0.0   \n",
              "4      0.000000  0.008212  0.020837  0.007940  0.026600  0.002663  0.0   \n",
              "...         ...       ...       ...       ...       ...       ...  ...   \n",
              "11774  0.993576  0.000011  0.000032  0.000000  0.000000  0.000011  0.0   \n",
              "11775  0.995717  0.000097  0.000034  0.000100  0.000000  0.000003  0.0   \n",
              "11776  0.995717  0.000007  0.000020  0.000000  0.000000  0.000008  0.0   \n",
              "11777  0.997859  0.000063  0.000158  0.000030  0.000010  0.000011  0.0   \n",
              "11778  1.000000  0.000134  0.000261  0.000119  0.000000  0.000011  0.0   \n",
              "\n",
              "             7         8         9   ...        11        12            13  \\\n",
              "0      0.005704  0.006634  0.007492  ...  0.003776  0.002872  5.459389e-03   \n",
              "1      0.009138  0.010127  0.010487  ...  0.005712  0.004177  7.376078e-03   \n",
              "2      0.010544  0.011000  0.013271  ...  0.006275  0.004601  8.928515e-03   \n",
              "3      0.013590  0.014034  0.016998  ...  0.008042  0.005942  1.156957e-02   \n",
              "4      0.012917  0.013971  0.015370  ...  0.007520  0.005473  1.067646e-02   \n",
              "...         ...       ...       ...  ...       ...       ...           ...   \n",
              "11774  0.000000  0.000000  0.000000  ...  0.000011  0.000011  6.465253e-07   \n",
              "11775  0.000000  0.000765  0.000000  ...  0.000097  0.000097  6.116130e-05   \n",
              "11776  0.000000  0.000000  0.000000  ...  0.000008  0.000008  0.000000e+00   \n",
              "11777  0.000000  0.000423  0.000000  ...  0.000057  0.000044  2.353352e-05   \n",
              "11778  0.000000  0.000999  0.000000  ...  0.000135  0.000126  3.116252e-05   \n",
              "\n",
              "             14        15        16        17        18        19        20  \n",
              "0      0.095791  0.000000  0.006920  0.006920  0.067039  0.033333  0.001496  \n",
              "1      0.089985  0.000000  0.017301  0.017301  0.067039  0.033333  0.001496  \n",
              "2      0.092888  0.000000  0.003460  0.003460  0.067039  0.033333  0.001496  \n",
              "3      0.089985  0.000000  0.020761  0.020761  0.067039  0.033333  0.001496  \n",
              "4      0.087083  0.000000  0.006920  0.006920  0.067039  0.033333  0.001496  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "11774  0.001451  0.000000  0.000000  0.000000  0.050279  0.000000  0.000000  \n",
              "11775  0.026125  0.000000  0.006920  0.006920  0.044693  0.000000  0.000000  \n",
              "11776  0.000000  0.000000  0.000000  0.000000  0.044693  0.000000  0.000000  \n",
              "11777  0.008708  0.333333  0.006920  0.006920  0.011173  0.033333  0.000374  \n",
              "11778  0.010160  0.000000  0.000000  0.000000  0.033520  0.000000  0.000000  \n",
              "\n",
              "[11779 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scalers = {}\n",
        "hs = []\n",
        "for col in corr_cols:\n",
        "    a = file_2_data[col].to_numpy().reshape(-1, 1)\n",
        "    scalers[col] = MinMaxScaler()\n",
        "    scalers[col].fit(a)\n",
        "    hs.append(scalers[col].transform(a))\n",
        "# hs.append(file_2_data['рейтинг'].to_numpy().reshape(-1, 1))\n",
        "x_data_scaled = pd.DataFrame(np.hstack(hs))\n",
        "\n",
        "display(x_data_scaled.shape)\n",
        "display(x_data_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "CLASSES_CNT = len(file_2_data['рейтинг'].unique())\n",
        "y_data = utils.to_categorical(file_2_data['рейтинг'], CLASSES_CNT)\n",
        "# display(CLASSES_CNT)\n",
        "# display(y_data[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6936, 21)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(6936, 4)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(868, 21)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(868, 4)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(868, 21)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(868, 4)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def split(x_data, y_data, train_size = 0.8, valid_test_ratio = 0.5):\n",
        "    x_train, x_valid_test, y_train, y_valid_test = train_test_split(x_data, y_data, train_size = train_size, random_state = 42)\n",
        "    x_test, x_valid, y_test, y_valid = train_test_split(x_valid_test, y_valid_test, test_size = valid_test_ratio, random_state = 42)\n",
        "    return (x_train, y_train, x_valid, y_valid, x_test, y_test)\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "x_valid = []\n",
        "y_valid = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "min_length = file_2_data['рейтинг'].value_counts().min()\n",
        "\n",
        "for i in range(CLASSES_CNT):\n",
        "    mask = file_2_data['рейтинг'] == i\n",
        "    splitted_data = split(x_data_scaled[mask][: min_length], y_data[mask][: min_length])\n",
        "    x_train.append(splitted_data[0])\n",
        "    y_train.append(splitted_data[1])\n",
        "    x_valid.append(splitted_data[2])\n",
        "    y_valid.append(splitted_data[3])\n",
        "    x_test.append(splitted_data[4])\n",
        "    y_test.append(splitted_data[5])\n",
        "\n",
        "x_train = np.concatenate(x_train)    \n",
        "y_train = np.concatenate(y_train)    \n",
        "x_valid = np.concatenate(x_valid)    \n",
        "y_valid = np.concatenate(y_valid)    \n",
        "x_test = np.concatenate(x_test)    \n",
        "y_test = np.concatenate(y_test) \n",
        "\n",
        "display(x_train.shape)\n",
        "display(y_train.shape)\n",
        "display(x_valid.shape)\n",
        "display(y_valid.shape)\n",
        "display(x_test.shape)\n",
        "display(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "shuffle_indices = np.arange(0, len(x_train), 1)\n",
        "np.random.shuffle(shuffle_indices)\n",
        "x_train_shuffled = x_train[shuffle_indices]\n",
        "y_train_shuffled = y_train[shuffle_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape = (x_train.shape[1])))\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(Dense(x_train.shape[1] * 4, activation = 'relu'))\n",
        "# model.add(Dense(500, activation = 'relu'))\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(Dense(250, activation = 'relu'))\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(Dense(125, activation = 'relu'))\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(Dense(y_data.shape[1], activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0001), metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "217/217 [==============================] - 6s 23ms/step - loss: 1.3611 - accuracy: 0.2846 - val_loss: 1.3349 - val_accuracy: 0.3018\n",
            "Epoch 2/100\n",
            "217/217 [==============================] - 5s 21ms/step - loss: 1.3212 - accuracy: 0.3658 - val_loss: 1.2950 - val_accuracy: 0.4009\n",
            "Epoch 3/100\n",
            "217/217 [==============================] - 5s 22ms/step - loss: 1.2886 - accuracy: 0.4080 - val_loss: 1.2644 - val_accuracy: 0.3882\n",
            "Epoch 4/100\n",
            "217/217 [==============================] - 5s 22ms/step - loss: 1.2645 - accuracy: 0.4017 - val_loss: 1.2422 - val_accuracy: 0.4032\n",
            "Epoch 5/100\n",
            "217/217 [==============================] - 5s 22ms/step - loss: 1.2494 - accuracy: 0.4106 - val_loss: 1.2292 - val_accuracy: 0.3986\n",
            "Epoch 6/100\n",
            "217/217 [==============================] - 5s 22ms/step - loss: 1.2400 - accuracy: 0.4112 - val_loss: 1.2208 - val_accuracy: 0.4090\n",
            "Epoch 7/100\n",
            "217/217 [==============================] - 5s 22ms/step - loss: 1.2344 - accuracy: 0.4146 - val_loss: 1.2165 - val_accuracy: 0.3871\n",
            "Epoch 8/100\n",
            "217/217 [==============================] - 5s 22ms/step - loss: 1.2310 - accuracy: 0.4122 - val_loss: 1.2121 - val_accuracy: 0.4101\n",
            "Epoch 9/100\n",
            "217/217 [==============================] - 5s 23ms/step - loss: 1.2287 - accuracy: 0.4136 - val_loss: 1.2101 - val_accuracy: 0.4090\n",
            "Epoch 10/100\n",
            "217/217 [==============================] - 5s 24ms/step - loss: 1.2267 - accuracy: 0.4187 - val_loss: 1.2084 - val_accuracy: 0.4136\n",
            "Epoch 11/100\n",
            "217/217 [==============================] - 5s 24ms/step - loss: 1.2253 - accuracy: 0.4141 - val_loss: 1.2071 - val_accuracy: 0.4136\n",
            "Epoch 12/100\n",
            "217/217 [==============================] - 5s 23ms/step - loss: 1.2241 - accuracy: 0.4170 - val_loss: 1.2078 - val_accuracy: 0.4124\n",
            "Epoch 13/100\n",
            "217/217 [==============================] - 5s 23ms/step - loss: 1.2227 - accuracy: 0.4164 - val_loss: 1.2065 - val_accuracy: 0.4240\n",
            "Epoch 14/100\n",
            "217/217 [==============================] - 5s 23ms/step - loss: 1.2219 - accuracy: 0.4229 - val_loss: 1.2052 - val_accuracy: 0.4124\n",
            "Epoch 15/100\n",
            "217/217 [==============================] - 5s 23ms/step - loss: 1.2213 - accuracy: 0.4185 - val_loss: 1.2040 - val_accuracy: 0.4147\n",
            "Epoch 16/100\n",
            "217/217 [==============================] - 5s 23ms/step - loss: 1.2204 - accuracy: 0.4214 - val_loss: 1.2031 - val_accuracy: 0.4251\n",
            "Epoch 17/100\n",
            "217/217 [==============================] - 5s 23ms/step - loss: 1.2194 - accuracy: 0.4259 - val_loss: 1.2021 - val_accuracy: 0.4194\n",
            "Epoch 18/100\n",
            "217/217 [==============================] - 5s 23ms/step - loss: 1.2190 - accuracy: 0.4220 - val_loss: 1.2015 - val_accuracy: 0.4205\n",
            "Epoch 19/100\n",
            "217/217 [==============================] - 5s 23ms/step - loss: 1.2181 - accuracy: 0.4233 - val_loss: 1.2016 - val_accuracy: 0.4263\n",
            "Epoch 20/100\n",
            "217/217 [==============================] - 5s 24ms/step - loss: 1.2176 - accuracy: 0.4255 - val_loss: 1.2009 - val_accuracy: 0.4182\n",
            "Epoch 21/100\n",
            "217/217 [==============================] - 5s 25ms/step - loss: 1.2170 - accuracy: 0.4255 - val_loss: 1.2000 - val_accuracy: 0.4228\n",
            "Epoch 22/100\n",
            "217/217 [==============================] - 6s 27ms/step - loss: 1.2162 - accuracy: 0.4247 - val_loss: 1.2002 - val_accuracy: 0.4320\n",
            "Epoch 23/100\n",
            " 10/217 [>.............................] - ETA: 4s - loss: 1.1684 - accuracy: 0.4906"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train_shuffled, y_train_shuffled, validation_data \u001b[39m=\u001b[39;49m (x_valid, y_valid), epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
            "File \u001b[0;32m~/Develop/AI/cars/.venv/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Develop/AI/cars/.venv/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/Develop/AI/cars/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Develop/AI/cars/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/Develop/AI/cars/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/Develop/AI/cars/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/Develop/AI/cars/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/Develop/AI/cars/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/Develop/AI/cars/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train_shuffled, y_train_shuffled, validation_data = (x_valid, y_valid), epochs = 100, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28/28 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, (ax1, ax2) \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, figsize \u001b[39m=\u001b[39m (\u001b[39m20\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[1;32m      2\u001b[0m fig\u001b[39m.\u001b[39msuptitle(\u001b[39m'\u001b[39m\u001b[39mГрафик процесса обучения модели\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m ax1\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mДоля верных ответов на обучающем наборе\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m ax1\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m], label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mДоля верных ответов на проверочном наборе\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m ax1\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mget_major_locator()\u001b[39m.\u001b[39mset_params(integer \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 5))\n",
        "fig.suptitle('График процесса обучения модели')\n",
        "ax1.plot(history.history['accuracy'], label = 'Доля верных ответов на обучающем наборе')\n",
        "ax1.plot(history.history['val_accuracy'], label = 'Доля верных ответов на проверочном наборе')\n",
        "ax1.xaxis.get_major_locator().set_params(integer = True)\n",
        "ax1.set_xlabel('Эпоха обучения')\n",
        "ax1.set_ylabel('Доля верных ответов')\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(history.history['loss'], label = 'Ошибка на обучающем наборе')\n",
        "ax2.plot(history.history['val_loss'], label = 'Ошибка на проверочном наборе')\n",
        "ax2.xaxis.get_major_locator().set_params(integer = True)\n",
        "ax2.set_xlabel('Эпоха обучения')\n",
        "ax2.set_ylabel('Ошибка')\n",
        "ax2.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "title = 'UseDesk, классификация'\n",
        "class_labels = [0, 1, 2, 3]\n",
        "cm = confusion_matrix(np.argmax(y_test, axis = 1), np.argmax(y_pred, axis = 1), normalize = 'true')\n",
        "cm = np.around(cm, 3)\n",
        "fig, ax = plt.subplots(figsize = (10, 10))\n",
        "ax.set_title(f'Нейросеть {title}: матрица ошибок нормализованная', fontsize = 18)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = class_labels)\n",
        "disp.plot(ax = ax)\n",
        "plt.gca().images[-1].colorbar.remove()\n",
        "plt.xlabel('Предсказанные классы', fontsize = 16)\n",
        "plt.ylabel('Верные классы', fontsize = 16)\n",
        "fig.autofmt_xdate(rotation = 45)\n",
        "plt.show()    \n",
        "\n",
        "print('-' * 100)\n",
        "print(f'Нейросеть: {title}')\n",
        "\n",
        "for cls in range(len(class_labels)):\n",
        "    cls_pred = np.argmax(cm[cls])\n",
        "    msg = 'ВЕРНО :-)' if cls_pred == cls else 'НЕВЕРНО :-('\n",
        "    label = f'\"{class_labels[cls]}\"'\n",
        "    predict = 100. * cm[cls, cls_pred]\n",
        "    print(f'Класс: {label:<20} {predict:3.0f}% сеть отнесла к классу: {label:<20} - {msg}')\n",
        "\n",
        "print(f'\\nСредняя точность распознавания: {100. * cm.diagonal().mean():3.0f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPDo9KCl0EBl85W8dNuuQze",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
